[["index.html", "Bayes Rules! Book Club Welcome", " Bayes Rules! Book Club The R4DS Online Learning Community 2022-08-12 Welcome Welcome to the bookclub! This is a companion for the book Bayes Rules! by Alicia A. Johnson, Miles Q. Ott, and Mine Dogucu (Chapman and Hall/CRC, copyright 2022, 9780367255398). This companion is available at r4ds.io/bayes_rules. This website is being developed by the R4DS Online Learning Community. Follow along, and join the community to participate. This companion follows the R4DS Online Learning Community Code of Conduct. "],["book-club-meetings.html", "Book club meetings", " Book club meetings Each week, a volunteer will present a chapter from the book (or part of a chapter). This is the best way to learn the material. Presentations will usually consist of a review of the material, a discussion, and/or a demonstration of the principles presented in that chapter. More information about how to present is available in the github repo. Presentations will be recorded, and will be available on the R4DS Online Learning Community YouTube Channel. "],["pace.html", "Pace", " Pace We‚Äôll try to cover 1 chapter/week, but‚Ä¶ ‚Ä¶It‚Äôs ok to split chapters when they feel like too much. We will try to meet every week, but will likely take some breaks for holidays, etc. Following the flow! Source: https://www.youtube.com/watch?v=zYYBtxHWE0A From: Richard McElreath, Statistical Rethinking videos "],["preface.html", "Preface ", " Preface "],["bayesian-statistics.html", "0.1 Bayesian statistics?", " 0.1 Bayesian statistics? Frequentist and Bayesian methods share: learning from data But Bayesian allows: new data + prior results easier to interpret shines when frequentist fails computational tools more accesible now "],["tips-and-tricks-from-the-authors.html", "0.2 Tips and tricks from the authors", " 0.2 Tips and tricks from the authors Learn by doing Embrace a growth mindset (we will do mistakes!) Interpret Bayes in a context (ethics and maybe more) Practice, practice, practice "],["set-up.html", "0.3 Set up", " 0.3 Set up Install rstan : https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started install.packages(c(&quot;bayesrules&quot;, &quot;tidyverse&quot;, &quot;janitor&quot;, &quot;rstanarm&quot;, &quot;bayesplot&quot;, &quot;tidybayes&quot;, &quot;broom.mixed&quot;, &quot;modelr&quot;, &quot;e1071&quot;, &quot;forcats&quot;), dependencies = TRUE) On linux (ubuntu 22) I had to update some dependencies. "],["the-authors.html", "0.4 The authors:", " 0.4 The authors: Alicia A. Johnson : Website https://ajohns24.github.io/portfolio/ Miles Q. Ott: https://twitter.com/Miles_Ott Mine Dogucu: https://twitter.com/MineDogucu "],["the-big-bayesian-picture.html", "Chapter 1 The Big (Bayesian) Picture", " Chapter 1 The Big (Bayesian) Picture Learning objectives: Learn to think like a Bayesian. Explore the foundations of a Bayesian data analysis and how they contrast with the frequentist alternative Learn a little bit about the history of the Bayesian philosophy "],["thinking-like-a-bayesian-14.html", "1.1 Thinking like a Bayesian 1/4", " 1.1 Thinking like a Bayesian 1/4 DiagrammeR::grViz(&quot; digraph thinking_bayesian{ # node statement node [shape = oval] a [label = &#39;Prior&#39;]; b [label = &#39;Data&#39;]; c [label = &#39;Posterior&#39;]; d [label = &#39;New data&#39;]; e [label = &#39;Posterior&#39;]; f [label = &#39;New data&#39;] g [style = invisible ] # edge statement a -&gt; c b -&gt; c c -&gt; e d -&gt; e f-&gt; g [style = dashed] e-&gt; g [style = dashed] }&quot;) Figure 1.1: A Bayesian knowledge-building diagram Both Bayesian and frequentist share a common goal: learn from data about the world around Both use data to fit nodels, make predictions and evaluate hypothesis "],["quiz-time.html", "1.2 Quiz time!", " 1.2 Quiz time! 4-5: frequentist 6-8: a bit of both 9-12: Bayesian TODO link to script and data in repo "],["thinking-like-a-bayesian-24.html", "1.3 Thinking like a Bayesian 2/4", " 1.3 Thinking like a Bayesian 2/4 1.3.1 Interpreting probability: Bayesian philosophy: relative plausibility of an event Frequentist philosophy: long-run relative frequency of a repeatable event "],["thinking-like-a-bayesian-34.html", "1.4 Thinking like a Bayesian 3/4", " 1.4 Thinking like a Bayesian 3/4 1.4.1 Bayesian balancing act Two claims: Zuofo claims he can predict the outcome of coin flip Kavya claims she can distinguish between natural and artificial sweeteners If both succeed with a 10/10 sucess rate what can we conclude from this? The frequentist approach will discard prior knowledge (it is harder to predict coin flip that having a sensitive palate to sweeteners) and the Bayesian want to use this prior knowledge. -&gt; How can we balance Prior and Data? "],["thinking-like-a-bayesian-44.html", "1.5 Thinking like a Bayesian 4/4", " 1.5 Thinking like a Bayesian 4/4 1.5.1 Asking question What‚Äôs the chance that I actually have the disease (a)? Versus I do not have the disease, What‚Äôs the chance that I would have gotten this positive test results (b)? # building data disease &lt;- c(rep(&quot;disease&quot;, 4), rep(&quot;no disease&quot;, 96)) a &lt;- &quot;test positive&quot; ; b &lt;- &quot;test negative&quot; test &lt;- c(rep(a, 3), b, rep(a, 9), rep(b, 87)) disease_status &lt;- data.frame(disease, test) # contingency table contingency_disease &lt;- table(disease_status) contingency_disease &lt;- addmargins(contingency_disease) knitr::kable(contingency_disease ) test negative test positive Sum disease 1 3 4 no disease 87 9 96 Sum 88 12 100 (a): 3 / 12 (b): 9 / 96 Analogy between (b) and p-value: it is more natural to study the uncertainty of a yet-unproven hypothesis than the uncertainty of data we have already observed.(authors‚Äôopinion) "],["quick-history-lesson.html", "1.6 Quick history lesson", " 1.6 Quick history lesson From stigmatized to being used in modeling COVID-19 rates. Why? advances in computing departure from tradition (what people learn is what people use) reevaluation of subjectivity : frequentist is also subjective and subjectivity is not any more a dirty word. "],["look-ahead.html", "1.7 Look ahead", " 1.7 Look ahead 1.7.1 4 units Bayesian foundations: 5 chapters Focus: models &amp; distributions (conjugate family) Posterior simulations &amp; analysis: 3 chapters Focus: when conjugate is not an option: MCMC then posterior analysis Bayesian regression &amp; classification Focus: extending unit 1 reponse variable (Y) with predictor variables (X) Hierarchical Bayesian models Focus: expanding unit 3 to accomodate and harness grouped data. "],["summary.html", "1.8 Summary", " 1.8 Summary Posterior knowledge &lt;- balancing information from data and prior knowledge More ‚Äúwaves‚Äùof data -&gt; refine knowledge (less effect of prior) With more and more data, two analysts will converge on the same posterior knowledge "],["resources-mentioned.html", "1.9 Resources mentioned", " 1.9 Resources mentioned This is a list of resources mentioned in the first meeting! 1.9.1 Other Bayesian books: Richard McElreath * book: https://xcelab.net/rm/statistical-rethinking/ * vid√©o: https://github.com/rmcelreath/stat_rethinking_2022 The ‚Äúpuppy‚Äù book by John K. Kruschke : https://sites.google.com/site/doingbayesiandataanalysis/ Introduction to Bayesian Thinking, Clyde, Centinkaya-Rundel et al similar level to our book Bayesian Data Analysis, Andrew Gelman more precise (and mathematical) Intro to Bayes Theorem, Wrath of Math, video Clear explanation of the meaning of given in statements like probability of A given B. $ P(A | B) $ 1.9.2 Drawing DAG (Directed Acyclic Graph) Pen and paper DiagrammeR: for drawing diagram, uses Graphviz or mermaid Dagitty: for causal diagrams 1.9.3 Podcast Learning Bayesian Statistics ep. 42 With Mine Dogucu "],["meeting-videos.html", "1.10 Meeting Videos", " 1.10 Meeting Videos 1.10.1 Cohort 1 Meeting chat log 00:06:01 Olivier: hello ! 00:06:47 Olivier: various links : https://r4ds.github.io/bookclub-bayes_rules/ 00:06:55 Olivier: https://docs.google.com/spreadsheets/d/18IDSOU2bfkD55kOB18qCB7Idbpiyp4_9qeWjkvE-Syc/edit#gid=0 00:09:44 Olivier: Let≈õ wait that everyone configure zoom :P 00:10:18 Gabby Palomo: I didn&#39;t see if anyone else signed up for this cohort. I imagine more people did, right? 00:10:46 Olivier: I do not know the number of participant 00:10:52 Olivier: I will have to ask 00:11:08 Will: Well hopefully. I&#39;m assuming for fellow Brits there are lots people celebrating the jubilee. 00:11:59 Gabby Palomo: ah that&#39;s true!! 00:12:10 erik.aalto@tocaboca.com: I‚Äôm not hearing anything, but I could hear recording in progress when I joined.. 00:12:24 Olivier: do you hear me ? 00:12:27 Gabby Palomo: There are 85 people in the slack channel so will see. 00:12:42 erik.aalto@tocaboca.com: Nope, cant hear anything:/ 00:13:15 Will: Yes I think I can hear Erik 00:13:45 erik.aalto@tocaboca.com: Darn, can‚Äôt hear anything‚Ä¶this is weird 00:13:57 Olivier: we hear you at least 00:14:03 erik.aalto@tocaboca.com: I hear the zoom notifs‚Ä¶like ‚Äùrecording in progress‚Äù 00:15:52 Olivier: it is fine 00:16:13 Olivier: is it better 00:17:24 Olivier: is it good now ? 00:17:41 Olivier: i restaart it 00:19:02 Olivier: working or not ? 00:19:20 Ronald Legere: Not yet‚Ä¶ there is a audio test thing in the audio settings menu 00:19:48 Olivier: good name 00:56:58 Ronald Legere: Can you link those podcasts to slack? Or here ;) 01:06:31 Olivier Leroy: DiagrammeR 1.10.2 Cohort 2 "],["bayes-rule.html", "Chapter 2 Bayes‚Äô Rule", " Chapter 2 Bayes‚Äô Rule Learning objectives: Explore foundational probability tools conditional probability: Probability of A given B \\(P(A|B)\\) joint probability: Probability of A and B occuring \\(P(A \\cap B)\\) marginal probability: Probability of an event \\(P(A)\\) Law of Total Probability: If a probability of an event is unknown it can be calculated using the know probability of other related event Conduct first formal Bayesian analysis Practice your Bayesian grammar Prior Likelihood Normalizing constant Simulate Bayesian models sample() sample_n() rbinon() "],["building-a-bayesian-model-for-events.html", "2.1 Building a Bayesian model for events", " 2.1 Building a Bayesian model for events First Data set ?? fake_news Figure 2.1: Bayesian knowledge-building diagram for wether or not the article is fake Two variables: - fake vs real - ! or not 2.1.1 Workflow: Prior probability model A model for interpreting the data Posterior probability model \\[ P(FakeNew = 0.4 ) \\quad and \\quad P(Real = 0.6) \\] \\[ P(B = 0.4 ) \\quad and \\quad P(B^c = 0.6) \\] Here \\(P(FakeNew)\\) : prior probability of an article to be a fake news Valid probability model : 1. accounts all event 2. assign probabilities for each event 3. sum to one \\(P(ExClam)\\) : probability that an article contains an exclamation mark in his title We know that if an article is fake news : 26.67% that the title contains ! and if it is not fake this is just 2.22%. \\[ P(Exclam|FakeNew) = 0.2667 \\quad and \\quad P(Exclam|Real = 0.0222) \\] This is a conditional probability. Conditional probability help know if B give us insight in A. If it does not provide any information it means that A and B event are independent (\\(P(A|B) = P(A)\\)). "],["normalizing-constant.html", "2.2 Normalizing constant", " 2.2 Normalizing constant \\(P(Exclam|FakeNew) = 0.2667 \\quad and \\quad P(Exclam|Real) = 0.0222)\\) are our likelihood, when we know A (!) we know that getting B (Fake news) is more likely. It is different that our prior probability. Then we need can calculate the joint probability (probability of observing A nd B for example), of each options (here it is half of them): \\[ P(Exclam \\cap FakeNew) = P(Exclam|FakeNew) P (Fakenew) = 0.2667 *0.4 = 0.1067 \\] \\[ P(PasExclam \\cap FakeNew ) = (1 - P(Exclam|FakeNew)) * P(FakeNew)) = (1 - 0.2667) * 0.4 = 0.2993 \\] Here \\(P(B)\\) is the marginal probability of B B &lt;- c(0.1067, 0.2933, 0.4) Bc &lt;- c(0.0133, 0.5867, 0.6) Total &lt;- c(0.12, 0.88, 1) joint_p &lt;- data.frame(B, Bc, Total, row.names = c(&quot;A&quot;, &quot;Ac&quot;, &quot;Total&quot;)) knitr::kable(joint_p) B Bc Total A 0.1067 0.0133 0.12 Ac 0.2933 0.5867 0.88 Total 0.4000 0.6000 1.00 \\(P(Exclam)\\) is our normalizing constant. Ok but we want \\(P(FakeNew|exlam)\\) ie \\(P(B|A)\\) \\[ P(FakeNew|exclam) = \\frac{P(exclam \\cap FakeNew)}{P(Exclam)} = \\frac{P(FakeNew)L(FakeNew|Exclam)}{P(Exclam)} \\] \\[ posterior = \\frac{prior . likelihood}{normalizing \\quad constant} = \\frac{0.4 * 0.2667}{0.12} = 0.889 \\] "],["posterior-simulation.html", "2.3 Posterior simulation", " 2.3 Posterior simulation This was a model. Now we will use a simulation! library(dplyr) library(ggplot2) set.seed(84735) # Define possible articles article &lt;- data.frame(type = c(&quot;real&quot;, &quot;fake&quot;)) # Define the prior model prior &lt;- c(0.6, 0.4) article_sim &lt;- dplyr::sample_n(article, size = 10000, weight = prior, replace = TRUE) # dats model article_sim &lt;- article_sim %&gt;% mutate(data_model = case_when(type == &quot;fake&quot; ~ 0.2667, type == &quot;real&quot; ~ 0.0222)) # Simulate exclamation point usage data &lt;- c(&quot;NoExclam&quot;, &quot;Exclam&quot;) set.seed(3) # Rbase simplier ? article_sim &lt;- article_sim %&gt;% group_by(1:n()) %&gt;% mutate(usage = sample(data, size = 1, prob = c(1 - data_model, data_model))) ggplot(article_sim, aes(x = type)) + geom_bar() + facet_wrap(~ usage) "],["example-pop-vs-soda-vs-coke.html", "2.4 Example Pop vs Soda vs Coke", " 2.4 Example Pop vs Soda vs Coke Expend TRUE/FALSE example with one with categories. "],["building-a-bayesian-model-for-random-variables-1n.html", "2.5 Building a Bayesian model for random variables (1/n)", " 2.5 Building a Bayesian model for random variables (1/n) 2.5.1 First step prior \\(\\pi\\) : skill of Kasparov relative to Deep Blue (random variable) Prior model of \\(\\pi\\): pi &lt;- c(0.2, 0.5, 0.8, &quot;total&quot;) # pmf : probability mass functions pmf &lt;- c(0.1, 0.25, 0.65, 1) prior_pi &lt;- data.frame(pi, pmf) knitr::kable(t(prior_pi)) pi 0.2 0.5 0.8 total pmf 0.10 0.25 0.65 1.00 "],["building-a-bayesian-model-for-random-variables-1n-1.html", "2.6 Building a Bayesian model for random variables (1/n)", " 2.6 Building a Bayesian model for random variables (1/n) 2.6.1 Binomial data model Y is the number of games (on 6 games) that Kasparov wins. Y our random variable: {0, 1, ‚Ä¶., 6} , depends on \\(\\pi\\) \\[f(y|\\pi) = P (Y = y|\\pi ) \\] \\(y\\) : any possible outcone If we assume games are independents (no effect on each other) and \\(\\pi\\) is fixed we can use the Binomial model. Y is the number of successes in a fixed number of trials (\\(n\\)) \\[ Y|\\pi \\sim Bin(n, \\pi) \\] \\[ f(y|\\pi) = \\begin{pmatrix} 6 \\\\y \\end{pmatrix} \\pi^y(1 - \\pi)^{6 - y} \\quad for \\quad y \\in \\begin{Bmatrix} 0, 1, 2, 3, 4, 5, 6 \\end{Bmatrix} \\] We can use the prior for \\(\\pi\\) and all \\(y\\) to calculate each probabilities. "],["building-a-bayesian-model-for-random-variables-1n-2.html", "2.7 Building a Bayesian model for random variables (1/n)", " 2.7 Building a Bayesian model for random variables (1/n) 2.7.1 Binomial likelihood function Kasparov only won one of six games. This is our data with \\(L(\\pi|y = 1)\\). We can calculate it for each \\(\\pi\\) value. What is more likely is that \\(pi\\) was 0.2. 2.7.2 Probability mass functions vs likelihood functions When \\(\\pi\\) is known the conditional pmf allows us to compare the probabilities of different possible value of data Y (y1, y2 ..) occuring with \\(pi\\) when Y = y is known the likelihood function allows us to to compare the relative values of \\(\\pi\\) (\\(\\pi_1, \\pi_2, etc ..\\)) 2.7.3 Normalizing constant Total probability that Kasparov would win Y = 1 game across all possible win probability of \\(\\pi\\) We apply the Law of Total Probability (the sum of all likelihood for each value of \\(\\pi\\) by the prior probailities of these \\(\\pi\\) values) \\[ f(y = 1) = L(\\pi = 0.2 | y = 1) f(\\pi = 0.2 ) + L(\\pi = 0.5 | y = 1) f(\\pi = 0.5 ) + L(\\pi = 0.8 | y = 1) f(\\pi = 0.8 ) +\\] \\[ f( y = 1) \\simeq 0.3932 * 0.1 + 0.0938 * 0.25 + 0.0015 * 0.65 \\simeq 0.0637 \\] 2.7.4 Posterior probability model We have the prior, the likelihod and the normalizing constant -&gt; Bayes Rules! \\[ posterior = \\frac{prior . likelihood}{normalizing \\quad constant} \\quad for \\in \\begin{Bmatrix} 0.2, 0 5, 0.8 \\end{Bmatrix} \\] 2.7.5 Posterior shortcut The normalizing constant, is a constant it appears in all posterior calculations. We can work with unnormalizied proabilities or we can divide each unnormalizied probability by the sum of each of them. \\[ posterior \\propto prior * likelihood \\] ## Posterior simulation # Define possible win probabilities chess &lt;- data.frame(pi = c(0.2, 0.5, 0.8)) # Define the prior model prior &lt;- c(0.10, 0.25, 0.65) # Simulate 10000 values of pi from the prior set.seed(84735) chess_sim &lt;- sample_n(chess, size = 10000, weight = prior, replace = TRUE) chess_sim &lt;- chess_sim %&gt;% mutate(y = rbinom(10000, size = 6, prob = pi)) # Focus on simulations with y = 1 win_one &lt;- chess_sim %&gt;% filter(y == 1) # Plot the posterior approximation ggplot(win_one, aes(x = pi)) + geom_bar() "],["links-shared-in-the-second-meeting.html", "2.8 Links shared in the second meeting", " 2.8 Links shared in the second meeting Bayesian probability for babies! (with cookies) : https://raw.githubusercontent.com/epimath/epid-814-materials/master/Lectures/BayesianEstimation.pdf Author: Marisa Eisenberg "],["meeting-videos-1.html", "2.9 Meeting Videos", " 2.9 Meeting Videos 2.9.1 Cohort 1 Meeting chat log 00:11:44 erik.aalto@tocaboca.com: Hello, sorry for joining late, happy to see you again üòÑ 00:36:06 Brendan Lam: https://www.youtube.com/watch?v=HZGCoVF3YvM 00:37:26 Erik: we‚Äôll utilize the following likelihood function notation &lt;poorly formatted paste&gt; 00:37:41 Erik: sorry for how the formatting above went‚Ä¶ 00:42:42 Lisa: to add to brendan&#39;s resource, here is a slide deck using cookies as an example: https://github.com/epimath/epid-814-materials/blob/master/Lectures/BayesianEstimation.pdf 01:02:00 Federica Gazzelloni: thanks 01:02:34 Federica Gazzelloni: I‚Äôd like to go back to the L(..|..) 01:02:35 Gabby Palomo: It was clear Olivier. Don‚Äôt worry!! 01:03:07 Federica Gazzelloni: just to understand how it works and what is the difference 01:03:43 Erik: Need to jump out! Thanks for today. 01:04:15 Lisa: I need to get back to work too. thank you for today! 01:04:58 Federica Gazzelloni: thanks 01:05:03 Federica Gazzelloni: I‚Äôll check that 2.9.2 Cohort 2 "],["the-beta-binomial-bayesian-model.html", "Chapter 3 The Beta-Binomial Bayesian Model", " Chapter 3 The Beta-Binomial Bayesian Model Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1.html", "3.1 SLIDE 1", " 3.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-2.html", "3.2 Meeting Videos", " 3.2 Meeting Videos 3.2.1 Cohort 1 Meeting chat log 00:10:55 Kasia Ozga: host disabled whitboard so we will not try it üòõ 00:30:25 Will Parbury: 3 Blue 1 Brown: Binomial distributions | Probabilities of probabilities, part 1 https://www.youtube.com/watch?v=8idr1WZ1A7Q Serrano.Academy: The Beta Distribution in 12 minutes! https://www.youtube.com/watch?v=juF3r12nM5A PsychEd: Milgram‚Äôs Obedience Experiment https://www.youtube.com/watch?v=cBDkJ-Nc3Ig 00:30:38 Federica Gazzelloni: thanks 00:35:29 Federica Gazzelloni: you can watch the fist two videos of advancedR cohort6 book club for how to make the notes 00:36:32 Federica Gazzelloni: https://www.youtube.com/playlist?list=PL3x6DOfs2NGjnCxGKeDNJUfPpRFI2hJjv 00:36:58 Lisa: thanks! 00:38:21 Federica Gazzelloni: to make the notes have a look at the first and the third videos 00:38:42 Federica Gazzelloni: just the begin 00:40:39 Kasia Ozga: v 00:40:52 Kasia Ozga: https://ben18785.shinyapps.io/distribution-zoo/ 00:44:06 Kasia Ozga: mean is alpha / (alpha +alpha) 00:44:25 Kasia Ozga: 0,4 = 1/alpha 3.2.2 Cohort 2 "],["balance-and-sequentiality-in-bayesian-analyses.html", "Chapter 4 Balance and Sequentiality in Bayesian Analyses", " Chapter 4 Balance and Sequentiality in Bayesian Analyses Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-1.html", "4.1 SLIDE 1", " 4.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-3.html", "4.2 Meeting Videos", " 4.2 Meeting Videos 4.2.1 Cohort 1 Meeting chat log 00:14:08 Brendan Lam: eventually! 4.2.2 Cohort 2 "],["conjugate-families.html", "Chapter 5 Conjugate Families", " Chapter 5 Conjugate Families Learning objectives: Practice building Bayesian models Familiarize yourself with conjugacy "],["greek-letters.html", "5.1 Greek letters", " 5.1 Greek letters \\(\\lambda\\) = lambda \\(\\mu\\) = mu \\(\\sigma\\) = sigma \\(\\tau\\) = tau \\(\\theta\\) = theta This our last chapter on Bayesian foundations! "],["revisiting-choice-of-prior.html", "5.2 Revisiting choice of prior", " 5.2 Revisiting choice of prior Flexibility Computational ease: posterior easy to build Interpretability 5.2.1 Reminder the Beta-Binomial Model: Prior: \\(Beta (\\alpha, \\beta)\\) Data model: \\(Y = y \\quad for \\quad Bin(n, \\pi)\\) Posterior: \\(Beta(\\alpha + y, \\beta = n - y)\\) "],["joy.html", "5.3 Joy!", " 5.3 Joy! (yes I know it was the other way!) "],["gamma-poisson-conjugate-family-18.html", "5.4 Gamma-Poisson conjugate family 1/8", " 5.4 Gamma-Poisson conjugate family 1/8 We are going to do a model to estimate the number of fraud risk phone call: 5.4.1 Prior: rate \\(\\tau \\approx\\) 5 number of phone call / day can range from 2-7 "],["gamma-poisson-conjugate-family-28.html", "5.5 Gamma-Poisson conjugate family 2/8", " 5.5 Gamma-Poisson conjugate family 2/8 5.5.1 Poisson data model: \\(Y =\\) number of independant event that occur in a fixed ammount of time \\[Y|y \\sim Pois(\\tau) \\] Probability mass function: \\[ f(y|Y) = \\frac{\\tau^ye^-\\tau}{y!} \\quad for y \\in \\{0, 1, 2, ...\\} \\] (sum to 1) \\[E(Y|\\tau) = Var(Y|\\tau) = \\tau \\] "],["gamma-poisson-conjugate-family-38.html", "5.6 Gamma-Poisson conjugate family 3/8", " 5.6 Gamma-Poisson conjugate family 3/8 5.6.1 Poisson pmfs with different \\(\\tau\\) "],["gamma-poisson-conjugate-family-48.html", "5.7 Gamma-Poisson conjugate family 4/8", " 5.7 Gamma-Poisson conjugate family 4/8 5.7.1 Joint probability mass function We have pmf for each day but if we want for \\(n\\) day we need to use joint probably mass function. (product of every pmf) \\[L(\\tau|\\overrightarrow{y}) = \\frac{\\tau^{\\sum y_i e^{-n\\tau}}}{\\prod_{i=n}^{n} y!} \\propto e^{-n\\tau} \\tau^{\\sum y_i}\\] We just need : \\(n\\) and \\(\\sum y_i\\) "],["gamma-poisson-conjugate-family-58.html", "5.8 Gamma-Poisson conjugate family 5/8", " 5.8 Gamma-Poisson conjugate family 5/8 5.8.1 Potential priors? \\(\\tau\\) is postif and continuous We have 3 probability models : Gamma : \\(f(\\tau) \\propto \\tau^{s-1} e^{-r\\tau}\\) Weibull : \\(f(\\tau) \\propto \\tau^{s-1} e^{(-r\\tau)^s}\\) F : \\(f(\\tau) \\propto \\tau^{s/2 - 1} (1 + \\tau) ^ -s\\) Quiz! Which one ? "],["gamma-poisson-conjugate-family-68.html", "5.9 Gamma-Poisson conjugate family 6/8", " 5.9 Gamma-Poisson conjugate family 6/8 5.9.1 Gamma prior : Gamma and Exponential models \\(\\tau\\) continuous random variable but can only take + value \\[\\tau \\sim Gamma(s, r)\\] Probability density functions: \\[f(\\tau) = \\frac{r^s}{\\Gamma (s)} \\tau^{s - 1} e^{-r\\tau} \\quad for \\quad \\tau &gt; 0 \\] \\[ E(\\tau) = \\frac{s}{r} ; Mode(\\tau) = \\frac{s - 1}{r} \\quad for \\quad s \\geq 1; Var(\\tau) = \\frac{s}{r^2} \\] When s = 1 -&gt; Exponenial model = Gamma(1,r) \\[\\tau \\sim Exp(r)\\] "],["gamma-poisson-conjugate-family-6n.html", "5.10 Gamma-Poisson conjugate family 6/n", " 5.10 Gamma-Poisson conjugate family 6/n 5.10.1 Quiz! Gamma when s &gt; r ? Gamme when s &lt; r ? More variability in Gamma(20, 20) or Gamma(20, 100) ? dashed = modes solid = means "],["gamma-poisson-conjugate-family-78.html", "5.11 Gamma-Poisson conjugate family 7/8", " 5.11 Gamma-Poisson conjugate family 7/8 5.11.1 Applications! \\[ E(\\tau) = \\frac{s}{r} \\approx 5\\] -&gt; we need \\(s = 5r\\) Trial and error: bayesrules::plot_gamma(shape = 10, rate = 2) Yeahhhh! we have a Prior! "],["gamma-poisson-conjugate-family-88.html", "5.12 Gamma-Poisson conjugate family 8/8", " 5.12 Gamma-Poisson conjugate family 8/8 5.12.1 Gamma-Poisson conjugacy Now need a posterior! \\[ \\tau|\\overrightarrow{y} \\sim Gamma(s + \\sum y_i, r +n) \\] We have: Gamma(10,2) and as data: \\(\\overrightarrow{y} = (6 + 2 + 2+ 1 )\\) , \\(n = 4\\) \\[\\sum_{i = 1}^{4} = 6 + 2 + 2 + 1 =11\\] \\[\\overline{y} = \\frac{\\sum_{i = 1}^{4}}{4} = 2.75\\] \\[L(\\tau|\\overrightarrow{y}) = \\frac{\\tau^ye^{-n\\tau}}{y!}\\] \\[L(\\tau|\\overrightarrow{y}) = \\frac{\\tau^{11}e^{-4\\tau}}{6!2!2!1!} \\propto \\tau^{11}e^{-4\\tau}\\] bayesrules::plot_poisson_likelihood(y = c(6, 2, 2, 1), lambda_upper_bound = 10) We have prior, data, likelihood -&gt; posterior \\[Gamma(10, 2) \\longrightarrow Gamma(s + \\sum y_i, r +n)\\] \\[\\tau|\\overrightarrow{y} \\sim Gamma(21, 6) \\] bayesrules::plot_gamma_poisson(shape = 10, rate = 2, sum_y = 11, n = 4) "],["normal-normal-conjugate-family.html", "5.13 Normal-Normal conjugate family", " 5.13 Normal-Normal conjugate family TODO ‚Ä¶ Kitten Love GIFfrom Kitten GIFs "],["why-no-simulation-in-this-chapter.html", "5.14 Why no simulation in this chapter?", " 5.14 Why no simulation in this chapter? Hard to do! We moved from sample size 1 -&gt; \\(n\\) "],["critiques-of-conjugate-family.html", "5.15 Critiques of conjugate family", " 5.15 Critiques of conjugate family less flexible in selection the prior some does not allow flat prior "],["summary-1.html", "5.16 Summary", " 5.16 Summary conjugate priors are easy to compute/derive, interpretable Beta-Binomial: data Y is the number of successes in a set of \\(n\\) trials Gamma-Poisson: Y is a count with no upper limit Normal-Normal: Y is continuous "],["slide-1-2.html", "5.17 SLIDE 1", " 5.17 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-4.html", "5.18 Meeting Videos", " 5.18 Meeting Videos 5.18.1 Cohort 1 5.18.2 Cohort 2 Meeting chat log LOG ## ‚îÄ‚îÄ Attaching packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 1.3.2 ‚îÄ‚îÄ ## ‚úî tibble 3.1.8 ‚úî purrr 0.3.4 ## ‚úî tidyr 1.2.0 ‚úî stringr 1.4.0 ## ‚úî readr 2.1.2 ‚úî forcats 0.5.1 ## ‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ ## ‚úñ dplyr::filter() masks stats::filter() ## ‚úñ dplyr::lag() masks stats::lag() ## ## Attaching package: &#39;janitor&#39; ## ## ## The following objects are masked from &#39;package:stats&#39;: ## ## chisq.test, fisher.test ## ## ## Loading required package: StanHeaders ## ## rstan (Version 2.21.5, GitRev: 2e1f913d3ca3) ## ## For execution on a local, multicore CPU with excess RAM we recommend calling ## options(mc.cores = parallel::detectCores()). ## To avoid recompilation of unchanged Stan programs, we recommend calling ## rstan_options(auto_write = TRUE) ## ## ## Attaching package: &#39;rstan&#39; ## ## ## The following object is masked from &#39;package:tidyr&#39;: ## ## extract ## ## ## This is bayesplot version 1.9.0 ## ## - Online documentation and vignettes at mc-stan.org/bayesplot ## ## - bayesplot theme set to bayesplot::theme_default() ## ## * Does _not_ affect other ggplot2 plots ## ## * See ?bayesplot_theme_set for details on theme setting "],["approximating-the-posterior.html", "Chapter 6 Approximating the Posterior", " Chapter 6 Approximating the Posterior Learning objectives: Implement and examine the limitations of using grid approximation to simulate a posterior model. Explore the MCMC posterior simulation using R Learn several Markov chain diagnostics for examining the quality of an MCMC posterior simulation. N.B. We will learn more about how MCMC works in the next chapter! "],["motivation-for-approximations.html", "6.1 Motivation for approximations", " 6.1 Motivation for approximations Remember we are trying to compute the posterior distribution: \\[ f\\left(\\theta | y \\right) = \\frac{f(\\theta)L(\\theta | y)}{f(y)} \\] In previous examples (conjugate priors) we were able to do this analytically Numerator - no issue, we specify these distributions. Denominator - Can be difficult or intractable to compute the denominator f(y) ! \\[ f(y) = \\int_{\\theta_1}\\int_{\\theta_2} ... \\int_{\\theta_k}f(\\theta)L(\\theta | y) d\\theta_k ... d\\theta_1 d\\theta_2 \\] Solution? Aapproximate the posterior via simulation! "],["grid-approximaiton.html", "6.2 Grid Approximaiton", " 6.2 Grid Approximaiton Discretized approximation of the posterior. Method of producing samples: Define a grid of possible values of the parameters \\(\\theta\\), Evaluate the numerator at each possible value Obtain a discrete approximation of \\(f(\\theta|y)\\) by normalizing the results (i.e.¬†divide by the sum!) Randomly sample the grid values using the probabilities determined in step 3. "],["beta-binomial-example-grid.html", "6.3 Beta Binomial Example (Grid)", " 6.3 Beta Binomial Example (Grid) \\[ Y|\\pi \\sim Bin(10,\\pi)\\\\ \\pi \\sim Beta(2,2)\\] Observe \\(Y=9\\) successes. # Step 1: Define grid grid_data &lt;- data.frame(pi_grid = seq(from = 0, to = 1, length = 100)) # Step 2: Evaluate numerator grid_data &lt;- grid_data %&gt;% mutate(prior = dbeta(pi_grid, 2, 2), likelihood = dbinom(9, 10, pi_grid)) %&gt;% mutate( unnormalized = prior*likelihood) # Step 3: Normalize! grid_data &lt;- grid_data %&gt;% mutate(posterior = unnormalized/sum(unnormalized)) ggplot(grid_data, aes(x = pi_grid, y = posterior)) + geom_point() + geom_segment(aes(x = pi_grid, xend = pi_grid, y = 0, yend = posterior)) Sample from this posterior (Step 4) set.seed(84735) #BAYES post_sample &lt;- sample_n(grid_data, size = 10000, weight = posterior, replace = TRUE) ggplot(post_sample, aes(x = pi_grid)) + geom_histogram(aes(y = ..density..), color = &quot;white&quot;, binwidth = 0.05) + stat_function(fun = dbeta, args = list(11, 3)) + lims(x = c(0, 1)) ## Warning: Removed 2 rows containing missing values (geom_bar). We can compute any summary statistics from the samples (or from the grid posterior itself!) "],["mcmc.html", "6.4 MCMC", " 6.4 MCMC Curse of dimensionality -&gt; Grid approximation is limited to cases with only a few parameters. Markov Chain Monte Carlo produces a Markov chain of samples to approximate posterior. Markov Chain: \\(\\theta^{(i+1)} \\sim f(\\theta^{(i+1)} | \\theta^{(i)}, y)\\) Monte Carlo: Random samples from chain. Samples are not directly from the posterior and are not independent! More on how it works in next chapter. But we can just jump in with rstan "],["beta-binomial-mcmc.html", "6.5 Beta-Binomial (MCMC)", " 6.5 Beta-Binomial (MCMC) # define model in stan language bb_model &lt;- &quot; data { int&lt;lower = 0, upper = 10&gt; Y; } parameters { real&lt;lower = 0, upper = 1&gt; pi; } model { Y ~ binomial(10, pi); pi ~ beta(2, 2); } &quot; # use stan to simulate posterior bb_sim &lt;- stan(model_code = bb_model, data = list(Y = 9), chains = 4, iter = 5000*2, seed = 84735) Uses 4 chains and 10000 samples of which 1/2 are discarded by default for burn-in Result is a stanfit object, which can be used to extract the samples # for examining using view chains &lt;- as.data.frame(as.array(bb_sim, pars = &quot;pi&quot;)) # look at a zoom in of the sample trace mcmc_trace(bb_sim, pars = &quot;pi&quot;, window = c(50,100),size =0.1) Trace shows the samples exploring the parameter space but also illustrates non-zero autocorrelation. We can also plot the resulting distribution of samples (book shows that this is close to beta-binomial expected) mcmc_dens(bb_sim, pars = &quot;pi&quot;) + yaxis_text(TRUE) + ylab(&quot;density&quot;) "],["markov-chain-diagnostics.html", "6.6 Markov chain diagnostics", " 6.6 Markov chain diagnostics Primary tools: Trace plots Effective sample size Autocorrelation R-hat With trace plots, look for good mixing and compare parallel chains. Effective sample size takes into account the correlation between samples. (best if &gt; 10% of actual samples) neff_ratio(bb_sim, pars = c(&quot;pi&quot;)) ## [1] 0.3472187 Autocorrelation measures the correlation between pairs of Markov chain values that are Lag ‚Äústeps‚Äù apart mcmc_acf(bb_sim, pars = &quot;pi&quot;) R-hat is the ratio of the variability between chains to the variability within chains. R-hat &gt; 1.05 is cause for concern. rhat(bb_sim, pars=&quot;pi&quot;) ## [1] 1.000393 "],["summary-2.html", "6.7 Summary", " 6.7 Summary More sophisticated Bayesian models often require approximations Learned about two methods: Grid Approximation (straightforward but limited) MCMC (more flexible) Learned some MCMC diagnostics Next chapter, MCMC under the hood "],["meeting-videos-5.html", "6.8 Meeting Videos", " 6.8 Meeting Videos 6.8.1 Cohort 1 6.8.2 Cohort 2 Meeting chat log LOG "],["mcmc-under-the-hood.html", "Chapter 7 MCMC under the Hood", " Chapter 7 MCMC under the Hood Learning objectives: Conceptual understanding of how Markov chain algorithms work Explore Metropolis-Hastings algorithm Implement it with the Normal-Normal "],["the-big-idea-12.html", "7.1 The big idea 1/2", " 7.1 The big idea 1/2 We are going to use a Normal-Normal model: \\[ Y|\\mu \\sim Norm(\\mu, 0.75^2)\\] \\[ \\mu \\sim Norm(0, 1^2) \\] Observed outcome 6.25: \\[ \\mu|(Y = 6.25) \\sim Norm(4, 0.6^2)\\] Main idea: chain need to spend more time around \\(\\mu\\) value. Remember \\(\\mu^{i+1}\\) is dependant of \\(\\mu^{i}\\). How are we going to visit every part of the posterior dustribution: step 1 : propose a random location \\(\\mu&#39;\\) (I prefer \\(\\mu_{proposal}\\)) for the nex stop step 2 : Decide whether to: go to the proposed location: \\(\\mu_{proposal} = \\mu^{i+1}\\) stay at the current location: \\(\\mu = \\mu^{i+1}\\) Monte Carlo algorithm: step 1 propose location: draw \\(\\mu\\) from posterior model with \\(pdf \\quad f(\\mu|y)\\) step 2 : Go there "],["the-big-idea-22.html", "7.2 The big idea 2/2", " 7.2 The big idea 2/2 But we are using MCMC to approximate this pdf (so we can‚Äôt sample it). For we are going to use two tricks: We do know that \\(f(u|y = 6.25) \\propto f(\\mu)L(u|y = 6.25)\\) For step 1 we can use an other model or distribution to generate proposals \\[ \\mu_{proposal}|\\mu \\sim Unif(\\mu - w, \\mu, + w) \\] with pdf: \\[ q(\\mu&#39;|\\mu) = \\frac{1}{2 w}\\] This give us a way for doing step1! "],["the-metropolis-hastings-algorithm.html", "7.3 The Metropolis-Hastings algorithm", " 7.3 The Metropolis-Hastings algorithm step 1: ok : \\(q(\\mu_{proposal}|\\mu)\\) step 2: we are going to calculate an acceptance probability: \\[\\alpha = \\{1, \\frac{f(\\mu_{proposal}) L(\\mu_{proposal}|y) q(\\mu|\\mu_{proposal})}{f(\\mu)L(\\mu|y) q(\\mu_{proposal|\\mu})} \\}\\] Because the Uniform proposal model is symmetric: \\[ q(\\mu_{proposal}|\\mu) = q(\\mu|\\mu_{proposal})\\] Then after multiplying by \\(f(y)\\) we have now: \\[ \\alpha = min\\{1, \\frac{f(\\mu_{proposal}|y)}{f(\\mu|y)} \\} \\] This ration is equivalent to the unnormalized posterior. Two scnearios: Scenario 1: \\(f(\\mu_{proposal}|y) \\geq f(\\mu|y)\\) -&gt; \\(\\alpha = 1\\) we are moving Scenario 2: $f(_{proposal}|y) &lt; f(|y) $ then we move according to the probability \\(\\alpha\\) one_mh_iteration &lt;- function(w, current){ # STEP 1: Propose the next chain location proposal &lt;- runif(1, min = current - w, max = current + w) # STEP 2: Decide whether or not to go there proposal_plaus &lt;- dnorm(proposal, 0, 1) * dnorm(6.25, proposal, 0.75) current_plaus &lt;- dnorm(current, 0, 1) * dnorm(6.25, current, 0.75) alpha &lt;- min(1, proposal_plaus / current_plaus) next_stop &lt;- sample(c(proposal, current), size = 1, prob = c(alpha, 1-alpha)) # Return the results return(data.frame(proposal, alpha, next_stop)) } set.seed(8) one_mh_iteration(w = 1, current = 3) ## proposal alpha next_stop ## 1 2.93259 0.8240205 2.93259 "],["implementing-the-metropolis-hastings.html", "7.4 Implementing the Metropolis-Hastings", " 7.4 Implementing the Metropolis-Hastings mh_tour &lt;- function(N, w){ # 1. Start the chain at location 3 current &lt;- 3 # 2. Initialize the simulation mu &lt;- rep(0, N) # 3. Simulate N Markov chain stops for(i in 1:N){ # Simulate one iteration sim &lt;- one_mh_iteration(w = w, current = current) # Record next location mu[i] &lt;- sim$next_stop # Reset the current location current &lt;- sim$next_stop } # 4. Return the chain locations return(data.frame(iteration = c(1:N), mu)) } library(ggplot2) set.seed(84735) mh_simulation_1 &lt;- mh_tour(N = 5000, w = 1) ggplot(mh_simulation_1, aes(x = iteration, y = mu)) + geom_line() ggplot(mh_simulation_1, aes(x = mu)) + geom_histogram(aes(y = ..density..), color = &quot;white&quot;, bins = 20) + stat_function(fun = dnorm, args = list(4,0.6), color = &quot;blue&quot;) ## Tuning the Metropolis-Hastings algorithm 7.4.1 Quiz! w = 0.01 or w = 100, or w = 1 "],["a-beta-binomial-example.html", "7.5 A Beta-Binomial example", " 7.5 A Beta-Binomial example 1 success in 2 trials \\[ Y|\\pi = bin(2, \\pi) \\] \\[ \\pi = Beta(2,3) \\] We are still playing ‚Äúpretend‚Äù We are moving for step 1 to an Uniform to a Beta model because we want \\(\\pi\\) to be [0,1]. And we will draw every step from this Beta model. -&gt; change in step 1 \\[\\alpha = min \\{1, \\frac{f(\\pi_{proposal}|y)q(\\pi)}{f(\\pi|y) q(\\pi_{proposal})} \\} \\] one_iteration &lt;- function(a, b, current){ # STEP 1: Propose the next chain location proposal &lt;- rbeta(1, a, b) # STEP 2: Decide whether or not to go there proposal_plaus &lt;- dbeta(proposal, 2, 3) * dbinom(1, 2, proposal) proposal_q &lt;- dbeta(proposal, a, b) # &lt;- new current_plaus &lt;- dbeta(current, 2, 3) * dbinom(1, 2, current) current_q &lt;- dbeta(current, a, b) # &lt;- new alpha &lt;- min(1, proposal_plaus / current_plaus * current_q / proposal_q) next_stop &lt;- sample(c(proposal, current), size = 1, prob = c(alpha, 1-alpha)) return(data.frame(proposal, alpha, next_stop)) } betabin_tour &lt;- function(N, a, b){ # 1. Start the chain at location 0.5 current &lt;- 0.5 # 2. Initialize the simulation pi &lt;- rep(0, N) # 3. Simulate N Markov chain stops for(i in 1:N){ # Simulate one iteration sim &lt;- one_iteration(a = a, b = b, current = current) # Record next location pi[i] &lt;- sim$next_stop # Reset the current location current &lt;- sim$next_stop } # 4. Return the chain locations return(data.frame(iteration = c(1:N), pi)) } "],["why-the-algorithm-works.html", "7.6 Why the algorithm works", " 7.6 Why the algorithm works If the algorithm works : \\[\\frac{\\mu \\rightarrow \\mu_{proposa}}{\\mu_{proposal} \\rightarrow \\mu} = \\frac{ f(\\mu_{proposal}|y)}{f(\\mu|y)}\\] "],["chapter-summary.html", "7.7 Chapter summary", " 7.7 Chapter summary Step 1 Propose a new chain location by drawing from a proposal pdf which is perhaps dependent upon the current location Determine whether accept the proposal: depends on how favorable its posterior plausibility is relative to the posterior plausibility of the current location "],["meeting-videos-6.html", "7.8 Meeting Videos", " 7.8 Meeting Videos 7.8.1 Cohort 1 Meeting chat log 00:00:12 Federica Gazzelloni: Hello! 00:58:29 olivier leroy: while (count_accept &lt; M) { count_draw &lt;- count_draw + 1 un_runif &lt;- runif(1) k &lt;- rbinom(prob = un_runif, size = 10, n = 1) if(k == kobs) { count_accept &lt;- count_accept + 1 post[count_accept] &lt;- un_runif } } 01:04:14 olivier leroy: https://www.youtube.com/watch?v=Qqz5AJjyugM&amp;list=PLDcUM9US4XdMROZ57-OIRtIK0aOynbgZN&amp;index=8&amp;pp=sAQB 7.8.2 Cohort 2 Meeting chat log LOG "],["posterior-inference-prediction.html", "Chapter 8 Posterior Inference &amp; Prediction", " Chapter 8 Posterior Inference &amp; Prediction Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-3.html", "8.1 SLIDE 1", " 8.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-7.html", "8.2 Meeting Videos", " 8.2 Meeting Videos 8.2.1 Cohort 1 Meeting chat log LOG "],["simple-normal-regression.html", "Chapter 9 Simple Normal Regression", " Chapter 9 Simple Normal Regression Learning objectives: Building simple linear regression model Interpret appropriate prior models Simulate posterior model of the regression parameters Utilize simulation result to build posterior understanding of relationship between response (\\(Y\\)) and predictors (\\(X\\)) build posterior predictive models of \\(y\\) 9.0.1 Begining of Unit 3! Congratulations on our progress! 9.0.2 News terms \\(Y \\rightarrow\\) Response variable \\(X_{i}, X_{2}, ..., X_{p} \\rightarrow\\) Predictors We want to analyze quantitative response : Regression We want to analyze categorical response: Classification In this chapter we will go with the Normal regression model. Our toy example will come from a bike sharing service. We will try to understand the demand for it service. We want a model of the number of rides/day. Poisson model is not valid here because we do not have an equal mean and variance. Instead we are going to go with a normal model: \\[Y_{i}|\\mu, \\sigma \\overset{ind}{\\sim} N(\\mu, \\sigma^2) \\] \\[ \\mu \\sim N(\\theta, \\tau^2) \\] \\[ \\sigma \\sim some \\; prior \\; model \\] Can‚Äôt we do better with a predictor? Here it will be the temperature in Fahrenheit. "],["building-the-regression-model.html", "9.1 Building the regression model", " 9.1 Building the regression model 9.1.1 Data model We will have n data pairs of bike ridership (\\(Y\\)) and temperature (\\(X\\)) : \\[\\{(Y_{1}, X_{1}), (Y_{2}, X_{2}), ..., (Y_{n}, X_{n}) \\}\\] Here prior knowledge suggest positive linear relationship between ridership and temperature: the warmer it is, the more likely people are using bike share service. We are now moving away from the global mean (\\(\\mu\\)) to local mean (\\(\\mu_{i}\\), where \\(i\\) is one day). If the relationship is linear : \\[ \\mu_{i} = \\beta_{0} + \\beta_{1}X_{i} \\] \\(\\beta_{0}\\) is the intercept coefficent but it is hard to interpret (would you rent bike when it is 0 degree F) \\(\\beta_{1}\\) is the Temperature coefficient it indicates the typical change in ridership for every one unit increase in temperature. In case we have just one quantitative predictor it is called the slope. We can plunk this assumption in our model : \\[ Y_{i}| \\beta_{0}, \\beta_{1}, \\sigma \\overset{ind}{\\sim} N(\\mu_{i}, \\sigma^2) \\; with \\quad \\mu_{i} = \\beta_{0} + \\beta_{1}X_{i} \\] As you can see \\(\\sigma\\) is now about variability from the local mean 9.1.1.1 Normal regression assumptions Structure of the data: accounting for \\(X\\), \\(Y\\) for one day is independent of an other day Structure of the relationship: Y can be written as a linear function of predictor X : \\(\\mu = \\beta_{0} + \\beta_{1}X\\) Structure of the variability: at any value of X, Y will vary normaly around \\(\\mu\\) with a consistent sd \\(\\sigma\\) 9.1.2 Specifying the priors We are going to use rstanarm : Rstan + arm = applied regression models 9.1.2.1 Quiz! What are our parameters ? Results \\[\\beta_{0}, \\beta_{1}, \\sigma\\] First assumption our parameters are independent \\[ \\beta_{0} \\sim N(m_{0}, s^2_{0} ) \\] \\[ \\beta_{1} \\sim N(m_{1}, s^2_{1} ) \\] \\(m_{0}, m_{1}, s_{0}, s_{1}\\) are parameters of parameters so they are : hyperparameters \\[\\sigma \\sim Exp(l).\\] (no idea about the dot, probably = not 0) 9.1.3 Putting it all together \\[ Y_{i}| \\beta_{0}, \\beta_{1}, \\sigma \\overset{ind}{\\sim} N(\\mu_{i}, \\sigma^2) \\; with \\quad \\mu_{i} = \\beta_{0} + \\beta_{1}X_{i} \\] \\[ \\beta_{0} \\sim N(m_{0}, s^2_{0} ) \\] \\[ \\beta_{1} \\sim N(m_{1}, s^2_{1} ) \\] \\[\\sigma \\sim Exp(l).\\] Model building one step at a time ! Y is discret or continuous \\(\\rightarrow\\) appropriate model for data Rewrite the mean of Y as a function of predictors X Identify unknow parameters in your model what can be the value of those parameters for defining prior "],["tuning-prior-models-for-regression-parameters.html", "9.2 Tuning prior models for regression parameters", " 9.2 Tuning prior models for regression parameters An average temperature day (65, 70 degree F) in DC: 3000-7000 riders with around 5000 For every one degree increase you get +100 riders \\(\\pm\\) 80 at any given Temperature daily ridership vary with a sd of 1250 rides We will work with centered data \\(\\beta_{0} \\rightarrow \\beta_{0c}\\) because : it is easier in this example this is what rstanarm use \\[ Y_{i}| \\beta_{0}, \\beta_{1}, \\sigma \\overset{ind}{\\sim} N(\\mu_{i}, \\sigma^2) \\; with \\quad \\mu_{i} = \\beta_{0} + \\beta_{1}X_{i} \\] \\[ \\beta_{0c} \\sim N(5000, 1000^2 ) \\tag{a.}\\] \\[ \\beta_{1} \\sim N(100, 40^2 \\tag{b.}) \\] \\[\\sigma \\sim Exp(0.0008). \\tag{c.}\\] The only hard part was using an eqution from chapter5: \\[E(\\sigma) = \\frac{1}{l} = 1250\\] It is good to simulate this prior and see what they look like but we will do that in the part about rstanarm prior later. "],["posterior-simulatiion.html", "9.3 Posterior simulatiion", " 9.3 Posterior simulatiion Now we want to update our prior with data to get a posterior simulation! # Load and plot data library(bayesrules);library(ggplot2) data(bikes) ggplot(bikes, aes(x = temp_feel, y = rides)) + geom_point(size = 0.5) + geom_smooth(method = &quot;lm&quot;, se = FALSE) ## `geom_smooth()` using formula &#39;y ~ x&#39; I am saving you from the triple integrals in the denominator of p 220 and we are jumping strait into MCMC! 9.3.1 Simulation via rstanarm bike_model &lt;- rstanarm::stan_glm( # data information rides ~ temp_feel, # &lt;- using a variation of the formula syntax ? data = bikes, family = gaussian, # &lt;- we assume normal data # Priors information prior_intercept = normal(5000, 1000), # normal diff de rnorm prior = normal(100, 40), prior_aux = exponential(0.0008), #notice the aux for auxiliary more after # MCMC information chains = 4, iter = 5000*2, seed = 84735) # STEP 1: DEFINE the model stan_bike_model &lt;- &quot; data { int&lt;lower = 0&gt; n; vector[n] Y; vector[n] X; } parameters { real beta0; real beta1; real&lt;lower = 0&gt; sigma; } model { Y ~ normal(beta0 + beta1 * X, sigma); beta0 ~ normal(-2000, 1000); beta1 ~ normal(100, 40); sigma ~ exponential(0.0008); } &quot; # STEP 2: SIMULATE the posterior stan_bike_sim &lt;- rstan::stan(model_code = stan_bike_model, # data is structured a bit differently data = list(n = nrow(bikes), Y = bikes$rides, X = bikes$temp_feel), # same MCMC chains = 4, iter = 5000*2, seed = 84735) The model will return 5000 x nb of chains simulation of our parameters. Rstanarm will change their name: \\(\\beta_{0} \\rightarrow (intercept)\\) (I think it is \\(\\beta_{0}\\) and not \\(\\beta_{0c}\\)) \\(\\beta_{1} \\rightarrow temp\\_feel\\) But \\(\\sigma\\) stay sigma. We need to check if the simulation went well for that we can? Stop teasing us! [X] check the effective sample size: neff_ratio [X] rhat [X] trace plot (fuzzy moustach) [X] overlay the density of each chains "],["interpreting-the-posterior.html", "9.4 Interpreting the posterior", " 9.4 Interpreting the posterior What we have is the density of each parameters. # Posterior summary statistics broom.mixed::tidy(bike_model, # it take our output from rstanarm::stan_glm effects = c(&quot;fixed&quot;, &quot;aux&quot;), # fixed is regression coef et aux is auxiliary ie sigma conf.int = TRUE, conf.level = 0.80) # A tibble: 4 x 5 term estimate std.error conf.low conf.high &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 (Intercept) -2194. 362. -2656. -1732. 2 temp_feel 82.2 5.15 75.6 88.8 3 sigma 1281. 40.7 1231. 1336. 4 mean_PPD 3487. 80.4 3385. 3591. Here we can get the posterior median relationship : \\[ -2194.24 + 82.16X \\] If we want a bigger picture: # Store the 4 chains for each parameter in 1 data frame bike_model_df &lt;- as.data.frame(bike_model) # Check it out nrow(bike_model_df) [1] 20000 head(bike_model_df, 3) (Intercept) temp_feel sigma 1 -2657 88.16 1323 2 -2188 83.01 1323 3 -1984 81.54 1363 # and use add_fiited_draws() from tidybayes # 50 simulated model lines bikes %&gt;% tidybayes::add_fitted_draws(bike_model, n = 50) %&gt;% ggplot(aes(x = temp_feel, y = rides)) + geom_line(aes(y = .value, group = .draw), alpha = 0.15) + geom_point(data = bikes, size = 0.05) # I did not evaluate the code here # you should test with more than 50 lines 9.4.0.1 Quiz! Do we have ample posterior evidence that there‚Äôs a positive association between ridership and temperature ? Stop teasing us! Visual evidence : 50 or more posterior scenarios that display positive relationship Numerical evidence from CI: 80% CI for \\(\\beta_{1}\\) range from 75.6 to 88.8 Numerical evidence from posterior probability # Tabulate the beta_1 values that exceed 0 bike_model_df %&gt;% mutate(exceeds_0 = temp_feel &gt; 0) %&gt;% tabyl(exceeds_0) # resuly exceeds_0 n percent TRUE 20000 1 Finally we can also use tidybayes::add_predicted_draws to simulate X data set that make good use of plausible value of \\(\\sigma\\) "],["posterior-prediction.html", "9.5 Posterior prediction", " 9.5 Posterior prediction 9.5.1 Quiz! Suppose a weather report indicates that tomorrow will be a 75-degree day in D.C. What‚Äôs your posterior guess of the number of riders that Capital Bikeshare should anticipate? Stop teasing us! One option is \\[ -2194.24 + 82.16 * 75 = 3967.76 \\] But this do not take into account : Sampling variability Posterior variability The posterior predictive nodel take that into account. We have an overall chance to observe \\(Y_{new}\\) and its parameters. We can approximate this posterior predictive model with our 20 000 sets of parameters. 9.5.2 Building a posterior predictive model # Predict rides for each parameter set in the chain set.seed(84735) predict_75 &lt;- bike_model_df %&gt;% mutate(mu = `(Intercept)` + temp_feel*75, # &lt;- our 75 degree y_new = rnorm(20000, mean = mu, sd = sigma)) # &lt;- sampling var. head(predict_75, 3) (Intercept) temp_feel sigma mu y_new 1 -2657 88.16 1323 3955 4838 2 -2188 83.01 1323 4038 3874 3 -1984 81.54 1363 4132 5196 Interesting point is mu (\\(\\mu\\)) Vs. y_new (\\(Y_{new}\\)). # Construct 80% posterior credible intervals predict_75 %&gt;% summarize(lower_mu = quantile(mu, 0.025), upper_mu = quantile(mu, 0.975), lower_new = quantile(y_new, 0.025), upper_new = quantile(y_new, 0.975)) lower_mu upper_mu lower_new upper_new 1 3843 4095 1500 6482 \\(\\mu\\) is average in readership for 75 degree \\(Y_new\\) is for a specific day (with 75 degree) =&gt; More accuracy in predicting an average than an unique point! 9.5.3 Posterior with rstanarm We have done it from ‚Äúscatch‚Äù but we can use rstanarm::posterior_predict() # Simulate a set of predictions set.seed(84735) shortcut_prediction &lt;- posterior_predict(bike_model, newdata = data.frame(temp_feel = 75)) "],["sequential-regression-modeling.html", "9.6 Sequential regression modeling", " 9.6 Sequential regression modeling We can have our data that come in sequences: phase_1 &lt;- bikes[1:30, ] phase_2 &lt;- bikes[1:60, ] phase_3 &lt;- bikes Bayes rules !figure 9.13 "],["using-default-rstanarm-priors.html", "9.7 Using default rstanarm priors", " 9.7 Using default rstanarm priors Authors recommend to you the default prior from rstanarm: bike_model_default &lt;- rstanarm::stan_glm( rides ~ temp_feel, data = bikes, family = gaussian, # here very specific prior on sd prior_intercept = normal(5000, 2.5, autoscale = TRUE), # &lt;- see autoscale arg. prior = normal(0, 2.5, autoscale = TRUE), prior_aux = exponential(1, autoscale = TRUE), chains = 4, iter = 5000*2, seed = 84735) prior_summary(bike_model_default) Priors for model &#39;bike_model_default&#39; ------ Intercept (after predictors centered) Specified prior: ~ normal(location = 5000, scale = 2.5) Adjusted prior: ~ normal(location = 5000, scale = 3937) Coefficients Specified prior: ~ normal(location = 0, scale = 2.5) Adjusted prior: ~ normal(location = 0, scale = 351) Auxiliary (sigma) Specified prior: ~ exponential(rate = 1) Adjusted prior: ~ exponential(rate = 0.00064) ------ See help(&#39;prior_summary.stanreg&#39;) for more details It enforce weakly informative priors using the scale of the data. Figure 9.1: Fig9.5 and 9.14 from Bayes Rules! "],["next-week-with-frederica.html", "9.8 Next week with Frederica", " 9.8 Next week with Frederica Cahpter 10: Evaluating Regression Models! "],["summary-3.html", "9.9 Summary", " 9.9 Summary Build a simple Bayesian Normal regression with reesponse and predictor quantitative We noved fron global mean to local mean with the help of linear dependence Build models data model priors models Tuning priors models fro regressions parameters rstanarm::stanglm(autoscale = TRUE) rstantools::prior_summary() Posterior simulation Simulation rstanarm::stan_glm() rstan::stan() Check the simulation bayesplot::neff_ratio() rstan::rhat() bayesplot::mcmc_trace() bayesplot::mcmc_dens_overlay() Interpreting the posterior broom.mixed::tidy() tidybayes::add_fitted_draws() tidybayes::add_predicted_draws() Posterior predictions By hand (dplyr mutate and summarize) rstanarm::posterio_predict() + rstantools::posterior_interval() "],["resources.html", "9.10 Resources:", " 9.10 Resources: Rstanarm vignette "],["meeting-videos-8.html", "9.11 Meeting Videos", " 9.11 Meeting Videos 9.11.1 Cohort 1 Meeting chat log LOG "],["evaluating-regression-models.html", "Chapter 10 Evaluating Regression Models", " Chapter 10 Evaluating Regression Models Learning objectives: Determine whether a model is fair Determine how wrong a model is Determine our model‚Äôs posterior predictive accuracy "],["more-question-to-ask.html", "10.1 More question to ask", " 10.1 More question to ask When we look at the Bayesian model results, it might be important to investigate a bit more about: How was the data collected? By whom and for what purpose was the data collected? How might the results of the analysis, or the data collection itself, impact individuals and society? What biases might be baked into this analysis? (#fig:10.1)Credits: https://godcgo.com/a-bike-friendly-washington-dc/ "],["verifying-normal-regression-assumptions.html", "10.2 Verifying Normal regression assumptions", " 10.2 Verifying Normal regression assumptions Assumption 1: Structure of the data independency Assumption 2: Structure of the relationship linearity Assumption 3 : Structure of the variability normality Our model-case is made of: number of Capital Bikeshare rides: \\(Y_{i}\\) temperature on day \\(i\\): \\(X_{i}\\) (#fig:10.2)Credits: dezeen.com Starting from a Regression Model: \\[ Y_{i} = \\beta_{0} + \\beta_{1}X_{i} \\] We look for an approximation of the real mean value: estimate mean value \\[Y_{i} \\approx\\mu_{i}\\] \\[ \\mu_{i} = \\beta_{0} + \\beta_{1}X_{i} \\] ‚Äú‚Ä¶To turn this into a Bayesian model, we must incorporate prior models for each of the unknown regression parameters‚Ä¶(ct.9.1.2)‚Äù with this model parameters: \\[ Y_{i}| \\beta_{0}, \\beta_{1}, \\sigma \\overset{ind}{\\sim} N(\\mu_{i}, \\sigma^2) \\; with \\quad \\mu_{i} = \\beta_{0} + \\beta_{1}X_{i} \\] we expect some good results as we consider 500 daily observations within the two-year period. The response variable ridership \\(Y\\) is likely to be correlated over time with other features such as temperature \\(X\\). ‚Äú‚Ä¶today‚Äôs ridership likely tells us something about tomorrow‚Äôs ridership. Yet much of this correlation, or dependence, can be explained by the time of year and features associated with the time of year‚Ä¶‚Äù ‚Äú‚Ä¶knowing the temperature on two subsequent days may very well ‚Äúcancel out‚Äù the time correlation in their ridership data‚Ä¶‚Äù We are tempted to conclude: the temperatures in one location are independent of those in neighboring locations, the temperatures in one month don‚Äôt tell us about the next. (#fig:10.3)Assumption1 It‚Äôs reasonable to assume that, in light of the temperature \\(X\\), ridership data \\(Y\\) is independent from day to day. We are looking for a centered value of the intercept: \\[ \\beta_{0c} \\sim N(m_{0}, s^2_{0})= N(5000, 1000^2 ) \\tag{a.}\\] \\[ \\beta_{1} \\sim N(m_{1}, s^2_{1}) = N(100, 40^2 \\tag{b.}) \\] \\[ \\sigma\\sim Exp(l) = Exp(0.0008 \\tag{c.}) \\] data(bikes) ## date rides temp_feel ## 1 2011-01-01 654 64.72625 ## 2 2011-01-03 1229 49.04645 ## 3 2011-01-04 1454 51.09098 ## 4 2011-01-05 1518 52.63430 ## 5 2011-01-07 1362 50.79551 ## 6 2011-01-08 891 46.60286 To evaluate assumptions 2 and 3 we conduct a posterior predictive check. Our first look was at the relationship between rides and temperature, and so at the consistency of the distribution. (#fig:10.7)Assumption 2 and 3 Given the combined model assumptions reasonable, the posterior model should be able to simulate ridership data very close to the original 500 rides observations. bike_model &lt;- rstanarm::stan_glm( rides ~ temp_feel, data = bikes, family = gaussian, prior_intercept = normal(5000, 1000), prior = normal(100, 40), prior_aux = exponential(0.0008), chains = 4, iter = 5000*2, seed = 84735, # suppress the output refresh=0) bike_model_df &lt;- as.data.frame(bike_model) first_set &lt;- head(bike_model_df, 1) first_set ## (Intercept) temp_feel sigma ## 1 -2040.536 80.44231 1280.101 beta_0 &lt;- first_set$`(Intercept)` beta_1 &lt;- first_set$temp_feel sigma &lt;- first_set$sigma set.seed(84735) one_simulation &lt;- bikes %&gt;% mutate(mu = beta_0 + beta_1 * temp_feel, simulated_rides = rnorm(500, mean = mu, sd = sigma)) %&gt;% select(temp_feel, rides, simulated_rides) one_simulation%&gt;%head ## temp_feel rides simulated_rides ## 1 64.72625 654 4020.319 ## 2 49.04645 1229 1746.346 ## 3 51.09098 1454 3068.930 ## 4 52.63430 1518 2496.768 ## 5 50.79551 1362 3065.187 ## 6 46.60286 891 3735.023 ggplot(one_simulation, aes(x = simulated_rides)) + geom_density(color = &quot;lightblue&quot;) + geom_density(aes(x = rides), color = &quot;darkblue&quot;)+ labs(title=&quot;One posterior simulated dataset of ridership (light blue)\\nalong with the actual observed ridership data (dark blue).&quot;)+ ggthemes::theme_fivethirtyeight()+ theme(plot.title = element_text(size=10)) Posterior predictive check Use the pp_check() function from {bayesplot} package included in the {rstanarm} package. It compares the observed outcome variable y to simulated datasets from the posterior predictive distribution. # Examine 50 of the 20000 simulated samples pp_check(bike_model,nreps = 50) + xlab(&quot;rides&quot;)+ labs(title=&quot;50 datasets of ridership simulated from the posterior (light blue)\\nalongside the actual observed ridership data (dark blue)&quot;) So, in general to check the last two assumptions you should: Assume a different data structure Make a transformation "],["how-accurate-are-the-posterior-predictive-models.html", "10.3 How accurate are the posterior predictive models?", " 10.3 How accurate are the posterior predictive models? Three approaches to evaluating predictive quality Posterior predictive summaries median absolute error (MAE) scaled median absolute error within_50 and within_95 set.seed(84735) prediction_summary(bike_model, data = bikes) ## mae mae_scaled within_50 within_95 ## 1 990.4453 0.7709476 0.438 0.966 set.seed(84735) predict_75 &lt;- bike_model_df %&gt;% mutate(mu = `(Intercept)` + temp_feel*75, y_new = rnorm(20000, mean = mu, sd = sigma)) # Plot the posterior predictive model ggplot(predict_75, aes(x = y_new)) + geom_density()+ geom_vline(aes(xintercept = 6228))+ labs(title=&quot;The posterior predictive model of ridership on October 22, 2012,\\na 75-degree day. The actual Y = 6228 riders observed that day are\\nmarked by the vertical line.&quot;)+ ggthemes::theme_fivethirtyeight()+ theme(plot.title = element_text(size=10)) set.seed(84735) predictions &lt;- posterior_predict(bike_model, newdata = bikes) dim(predictions) ## [1] 20000 500 ppc_intervals(bikes$rides, yrep = predictions, x = bikes$temp_feel, prob = 0.5, prob_outer = 0.95)+ labs(title=&quot;The posterior predictive medians (light blue dots),\\n50% prediction intervals (wide, short blue bars),\\nand 95% prediction intervals (narrow, long blue bars)\\nfor each day in the bikes dataset, along with the corresponding\\nobserved data points (dark blue dots).&quot;) Cross-validation To see how well our model generalizes to new data beyond our original sample, we can estimate these properties using cross-validation techniques. Train the model Test the model set.seed(84735) cv_procedure &lt;- prediction_summary_cv(model = bike_model, data = bikes, k = 10) cv_procedure$folds%&gt;%head ## fold mae mae_scaled within_50 within_95 ## 1 1 989.9688 0.7695714 0.46 0.98 ## 2 2 965.4630 0.7432483 0.42 1.00 ## 3 3 949.6831 0.7292722 0.42 0.98 ## 4 4 1018.8814 0.7911418 0.46 0.98 ## 5 5 1161.6688 0.9091497 0.36 0.96 ## 6 6 937.0211 0.7321570 0.46 0.94 cv_procedure$cv ## mae mae_scaled within_50 within_95 ## 1 1029.1 0.8014163 0.422 0.968 All we want is: (#fig:10.21)Two hypothetical posterior predictive pdfs for Y new, the yet unobserved ridership on a new day. The eventual observed value of y new, is represented by a dashed vertical line Expected log-predictive density (ELPD) ELPD measures the average log posterior predictive pdf, across all possible new data points. The higher the ELPD, the better. Higher ELPDs indicate greater posterior predictive accuracy when using our model to predict new data points. The loo() function in the {rstanarm} package utilizes leave-one-out cross-validation to estimate the ELPD of a given model: model_elpd &lt;- loo(bike_model) model_elpd$estimates ## Estimate SE ## elpd_loo -4289.034410 13.11464 ## p_loo 2.501565 0.16400 ## looic 8578.068821 26.22928 10.3.1 Improving posterior predictive accuracy Collect more data Use different or more predictors "],["how-good-is-the-mcmc-simulation-vs-how-good-is-the-model.html", "10.4 How good is the MCMC simulation vs how good is the model?", " 10.4 How good is the MCMC simulation vs how good is the model? How well our MCMC simulation approximates the model? Does the model fit? are the assumptions reasonable? is the model fair? does it produce good predictions? "],["extra-resources.html", "10.5 Extra resources:", " 10.5 Extra resources: The Impact of Weather Conditions on Capital Bikeshare Trips "],["meeting-videos-9.html", "10.6 Meeting Videos", " 10.6 Meeting Videos 10.6.1 Cohort 1 Meeting chat log LOG "],["extending-the-normal-regression-model.html", "Chapter 11 Extending the Normal Regression Model", " Chapter 11 Extending the Normal Regression Model Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-4.html", "11.1 SLIDE 1", " 11.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-10.html", "11.2 Meeting Videos", " 11.2 Meeting Videos 11.2.1 Cohort 1 Meeting chat log LOG "],["poisson-negative-binomial-regression.html", "Chapter 12 Poisson &amp; Negative Binomial Regression", " Chapter 12 Poisson &amp; Negative Binomial Regression Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-5.html", "12.1 SLIDE 1", " 12.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-11.html", "12.2 Meeting Videos", " 12.2 Meeting Videos 12.2.1 Cohort 1 Meeting chat log LOG "],["logistic-regression.html", "Chapter 13 Logistic Regression", " Chapter 13 Logistic Regression Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-6.html", "13.1 SLIDE 1", " 13.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-12.html", "13.2 Meeting Videos", " 13.2 Meeting Videos 13.2.1 Cohort 1 Meeting chat log LOG "],["naive-bayes-classification.html", "Chapter 14 Naive Bayes Classification", " Chapter 14 Naive Bayes Classification Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-7.html", "14.1 SLIDE 1", " 14.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-13.html", "14.2 Meeting Videos", " 14.2 Meeting Videos 14.2.1 Cohort 1 Meeting chat log LOG "],["hierarchical-models-are-exciting.html", "Chapter 15 Hierarchical Models are Exciting", " Chapter 15 Hierarchical Models are Exciting Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-8.html", "15.1 SLIDE 1", " 15.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-14.html", "15.2 Meeting Videos", " 15.2 Meeting Videos 15.2.1 Cohort 1 Meeting chat log LOG "],["normal-hierarchical-models-without-predictors.html", "Chapter 16 (Normal) Hierarchical Models without Predictors", " Chapter 16 (Normal) Hierarchical Models without Predictors Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-9.html", "16.1 SLIDE 1", " 16.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-15.html", "16.2 Meeting Videos", " 16.2 Meeting Videos 16.2.1 Cohort 1 Meeting chat log LOG "],["normal-hierarchical-models-with-predictors.html", "Chapter 17 (Normal) Hierarchical Models with Predictors", " Chapter 17 (Normal) Hierarchical Models with Predictors Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-10.html", "17.1 SLIDE 1", " 17.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-16.html", "17.2 Meeting Videos", " 17.2 Meeting Videos 17.2.1 Cohort 1 Meeting chat log LOG "],["non-normal-hierarchical-regression-classification.html", "Chapter 18 Non-Normal Hierarchical Regression &amp; Classification", " Chapter 18 Non-Normal Hierarchical Regression &amp; Classification Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-11.html", "18.1 SLIDE 1", " 18.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-17.html", "18.2 Meeting Videos", " 18.2 Meeting Videos 18.2.1 Cohort 1 Meeting chat log LOG "],["adding-more-layers.html", "Chapter 19 Adding More Layers", " Chapter 19 Adding More Layers Learning objectives: THESE ARE NICE TO HAVE BUT NOT ABSOLUTELY NECESSARY "],["slide-1-12.html", "19.1 SLIDE 1", " 19.1 SLIDE 1 ADD SLIDES AS SECTIONS (##). TRY TO KEEP THEM RELATIVELY SLIDE-LIKE; THESE ARE NOTES, NOT THE BOOK ITSELF. "],["meeting-videos-18.html", "19.2 Meeting Videos", " 19.2 Meeting Videos 19.2.1 Cohort 1 Meeting chat log LOG "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
